\chapter{Einleitung und Problemstellung}

Für Lehrkräfte an Hochschulen und Universitäten stellt das Prüfen und Bewerten studentischer Einreichungen eine zentrale, oftmals sehr zeitaufwändige Aufgabe dar. Insbesondere bei einer hohen Anzahl an Abgaben steigt der Korrekturaufwand erheblich, was den zeitlichen Rahmen für individuelles und qualitativ hochwertiges Feedback stark einschränken kann. Eine Untersuchung zeigt, dass vor allem die Bewertung studentischer Arbeiten als Hauptfaktor für Arbeitsbelastung und Beeinträchtigung des Wohlbefindens von Lehrkräften genannt wird (vgl. \cite{Jerrim.2021}). Im Bereich der Informatik betrifft dies insbesondere die Korrektur von Programmieraufgaben, bei denen jede Einreichung in Syntax und Semantik individuell gestaltet ist und dennoch konsistent und objektiv bewertet werden muss.

Einen Lösungsansatz bieten automatisierte Systeme zur Bewertung von Programmieraufgaben. Systematische Übersichtsarbeiten zeigen jedoch, dass viele dieser Systeme vorwiegend auf Unit-Tests oder statische Analysen setzen und meist lediglich generisches Feedback generieren (vgl. \cite{Messer.2023}). Ein praktisches Beispiel hierfür ist das an der Hochschule Trier eingesetzte System ASB - Automatische Software-Bewertung\footnote{\url{https://www.hochschule-trier.de/informatik/forschung/projekte/asb}}. Studierende laden dabei ihre bearbeiteten Aufgaben hoch, woraufhin das System prüft, ob alle erforderlichen Dateien vorhanden sind und die Benennungs- und Strukturvorgaben eingehalten wurden. Anschließend erfolgt eine dynamische Analyse durch Ausführung des Programms mit vordefinierten Testdaten. Entspricht die Ausgabe nicht den erwarteten Ergebnissen, wird eine Fehlermeldung generiert, die über die Funktionsfähigkeit einzelner Module oder des gesamten Programms informiert.

Das von solchen Systemen erzeugte Feedback dient in erster Linie der Orientierung, bietet jedoch meist wenig Unterstützung bei der Fehlersuche oder einer tiefergehenden Analyse der Lösung. Um die Qualität und Aussagekraft des Feedbacks zu erhöhen, könnten KI-gestützte Verfahren eingesetzt werden, die über rein statische oder testbasierte Ansätze hinausgehen.

Mit einem Schritt vor der Feedbackgenerierung befasst sich diese Arbeit. Ziel ist ein Verfahren zur KI-gestützten Clusterung studentischer Programmierlösungen zu entwickeln. Dabei sollen ähnliche Einreichungen anhand syntaktischer und semantischer Merkmale geclustert bzw. gruppiert werden, um es Lehrenden oder automatisierten Systemen zu ermöglichen, ein repräsentatives Beispiel pro Cluster auszuwählen. Dieses kann als Grundlage für ein ausführliches Feedback dienen, das anschließend an alle anderen Teilnehmer des Clusters weiterleitet wird. Auf diese Weise ließe sich der Korrekturaufwand deutlich reduzieren und gleichzeitig mehr Spielraum für individualisiertes und qualitativ hochwertiges Feedback schaffen.

Das folgende Kapitel gibt eine Einführung in das Thema, indem es grundlegende Begriffe klärt, die in dieser Arbeit benutzt wurden. Der größte Teil des Kapitels Vorgehensweise und Implementierung besteht in der Beschreibung wie das Programm implementiert wurde. Der Verlauf wird in vier Abschnitte beschrieben, wobei der Letzte das fertige Programm vorstellt. Der benutzte Code dazu ist im Anhang zu finden. Im anschließenden Kapitel wurden mittels dieses Programms Experimente mit gestellten Testdatensätze durchgeführt. Zum Schluss werden die Resultate der Arbeit und des Arbeitsverlauf und der Ausblick diskutiert.

Begriffe wie ''Verfahren'' und ''Algorithmen'', sowie ''Einreichungen'' und ''Lösungen'' werden im Projekt gleichbedeutend behandelt.
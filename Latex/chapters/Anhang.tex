\chapter{Anhang}

\begin{lstlisting}[language=Python, caption={Pipeline}, label={prco:Pipel}]
import os
import yaml
import warnings
import numpy as np
from utils.data_loader import DataLoader
from embeddings.embedding_model import EmbeddingModel
from dimReducer.dimension_reducer import DimensionReducer
from clustering.clustering_engine import ClusteringEngine
from utils.score_binning import ScoreBinner
from visualization.advanced_interactive_plot import AdvancedInteractivePlot
from evaluation.evaluation_metrics import EvaluationMetrics
from reporting.report_generator import ReportGenerator

# load config
def load_config(path="config.yaml"):
    with open(path, "r") as file:
        return yaml.safe_load(file)

def run_pipeline():
    config = load_config()

    # ignore warnings
    warnings.filterwarnings("ignore", category=FutureWarning)
    warnings.filterwarnings("ignore", category=UserWarning)

    # dynamically determine path
    base_path = os.path.dirname(os.path.abspath(__file__))
    input_path = os.path.join(base_path, config['data']['input_path'])

    # load data
    loader = DataLoader(config['data']['files_to_look_for'],
                        input_path,
                        config['data']['exclude_files'],
                        config['data']['exclude_folders'])
    code_snippets = loader.load_code_files(concat=True)

    # score bins
    scores = loader.get_scores()
    binned_scores = ScoreBinner.bin_scores(scores,
                                config['data']['score_bins'])
                                unique_bins = sorted(set(binned_scores))

    # Embedding object
    model = EmbeddingModel(config['embedding']['model'])
    cache_path = "cached_embeddings.npy"

    # save all info resulting in the loop to display it in one plot later
    all_embeddings, all_labels, all_filenames,
        all_parent_dirs, all_score_bins = [], [], [], [], []

    # filter solutions by score bin and prepare data for clustering
    for score_bin in unique_bins:
        print(f"\n==== Processing score_bin: {score_bin} ====")
        indices =
            [i for i, b in enumerate(binned_scores) if b == score_bin]

        if len(indices) < 4:
            continue    # Not enough solutions in score_bin

        snippets_bin = [code_snippets[i] for i in indices]
        filenames_bin = [loader.get_filenames()[i] for i in indices]
        parent_dirs_bin = [loader.get_parent_dirs()[i] for i in indices]

        # Embedding
        if os.path.exists(cache_path):
            embeddings_cache = np.load(cache_path)
            if len(embeddings_cache) >= len(snippets_bin):
                embeddings = embeddings_cache[:len(snippets_bin)]
            else:
                embeddings = np.array(
                    [model.get_embedding(code) for code in snippets_bin])
                np.save(cache_path, embeddings)
        else:
            embeddings = np.array(
                [model.get_embedding(code) for code in snippets_bin])
            np.save(cache_path, embeddings)

        # Dimension reduction
        reducer = DimensionReducer(config['dim_reduction']['algorithm'],
                                   config['dim_reduction']['params'])
        reduced_embeddings = reducer.reduce(embeddings)

        # Clustering
        clusterer = ClusteringEngine(config['clustering']['algorithm'],
                                     config['clustering']['params'])
        labels = clusterer.cluster(reduced_embeddings)

        # Evaluation
        results = EvaluationMetrics.evaluate(reduced_embeddings, labels)
        print("Evaluation results:", results)

        # Save info for interactive plot
        all_embeddings.extend(reduced_embeddings)
        all_labels.extend(labels)
        all_filenames.extend(filenames_bin)
        all_parent_dirs.extend(parent_dirs_bin)
        all_score_bins.extend([score_bin] * len(labels))

    # Interactive plot
    AdvancedInteractivePlot.plot(all_embeddings,
                                 all_labels,
                                 all_filenames,
                                 all_parent_dirs,
                                 all_score_bins)
    # Reporting
    ReportGenerator.generate_report(all_filenames,
                                    all_parent_dirs,
                                    all_labels,
                                    all_score_bins,
                                    config['data']['output_path'])
    print(f"Report saved to {config['data']['output_path']}")

if __name__ == "__main__":
    run_pipeline()
\end{lstlisting}


\begin{lstlisting}[language=Python, caption={Konfigurationsdatei}, label={prco:Konfigurationsdatei}]
embedding:
  model: "microsoft/codebert-base"  # embedding model for code snippets

dim_reduction:
# --- umap ---
  algorithm: "umap"
  params:
    n_components: 2
    n_neighbors: 15
    min_dist: 0.1
    metric: "euclidean"
    random_state: 42
    spread: 1.0
    learning_rate: 1.0
    init: "spectral"
# # --- pca ---
#   algorithm: "pca"
#   params:
#     n_components: 2
#     svd_solver: "auto"
#     random_state: 42
# # --- t-sne ---
#   algorithm: "tsne"
#   params:
#     n_components: 2
#     perplexity: 30.0
#     learning_rate: 200.0
#     n_iter: 1000
#     metric: "euclidean"
#     random_state: 42
#     init: "random"
#     early_exaggeration: 12.0
#     angle: 0.5
#     verbose: 0

clustering:
# --- hdbscan ---
  # algorithm: "hdbscan"
  # params:
  #   min_cluster_size: 2
  #   min_samples: 1
  #   cluster_selection_epsilon: 0.5
  #   metric: "euclidean"
  #   cluster_selection_algorithm: "eom"
  #   alpha: 1.0
  #   allow_single_cluster: false
# --- k-means ---
  algorithm: "kmeans"
  params:
    n_clusters: 5
    init: "k-means++"
    n_init: 10
    max_iter: 300
    random_state: 42

data:
  files_to_look_for: ".java"
  exclude_files: ["Miniprojekt1.java"]
  exclude_folders: ["100 Punkte"]
  input_path: "C:/Users/grego/Desktop/Loesungen/000TestingMedium000"
  output_path: "z_Output"
  score_bins:
  [[100, 100], [95, 99], [90, 94], [50, 89], [0, 49]]
\end{lstlisting}


\begin{lstlisting}[language=Python, caption={\texttt{data\_loader.py}}, label={prco:data-loader}]
import os

import os

class DataLoader:
    def __init__(self, file_name, data_path, 
            exclude_files=None, exclude_folders=None):
        self.data_path = data_path
        self.file_name = file_name
        self.filenames = []
        self.exclude_files = exclude_files if exclude_files else []
        self.exclude_folders = exclude_folders if exclude_folders else []
        self.parent_dirs = []


    def load_code_files(self, concat=False):
        if concat:
            return self.load_and_concat_code_files()

        code_snippets = []
        for root, dirs, files in os.walk(self.data_path):
            if any(excl in root for excl in self.exclude_folders):
                continue  # skip folder if it matches exclusion
            for file in files:
                if file.endswith(self.file_name) 
                and file not in self.exclude_files:
                    file_path = os.path.join(root, file)
                    self.filenames.append(file)
                    punktzahl_ordner = os.path.basename(root)
                    student_id = os.path.basename(os.path.dirname(root))

                    self.parent_dirs.append((student_id, punktzahl_ordner))
                    with open(file_path, "r", encoding="utf-8", 
                        errors="ignore") as f:
                        code_snippets.append(f.read())
        return code_snippets
    

    def load_and_concat_code_files(self):
        concatenated_solutions = []
        for root, dirs, files in os.walk(self.data_path):
            if any(excl in root for excl in self.exclude_folders):
                continue  # skip folder if it matches exclusion
            java_files = [f for f in files if f.endswith(self.file_name) 
                and f not in self.exclude_files]
            if java_files:
                solution_code = "" 
                for file in java_files:
                    file_path = os.path.join(root, file)
                    with open(file_path, "r", encoding="utf-8", 
                        errors="ignore") as f:
                        solution_code += f.read() + "\n"
                concatenated_solutions.append(solution_code)
                self.filenames.append(", ".join(java_files))
                
                score_dir = os.path.basename(root)
                student_id = os.path.basename(os.path.dirname(root))

                self.parent_dirs.append((student_id, score_dir))
        return concatenated_solutions
    
    
    def get_scores(self):
        scores = []
        for parent_tuple in self.parent_dirs:
            punktzahl_ordner = parent_tuple[1]
            try:
                score = int(''.join(filter(str.isdigit, 
                    punktzahl_ordner.split(' Punkte')[0].split()[-1])))
            except ValueError:
                score = -1
            scores.append(score)
        return scores


    def get_filenames(self):
        return self.filenames

    def get_parent_dirs(self):
        return self.parent_dirs
\end{lstlisting}


\begin{lstlisting}[language=Python, caption={\texttt{score\_binning.py}}, label={prco:score-binning}]
class ScoreBinner:
    @staticmethod
    def bin_scores(scores, bins):
        binned_labels = []
        for score in scores:
            binned_label = None
            for low, high in bins:
                if low <= score <= high:
                    binned_label = f"{low}-{high}"  # label string for bin
                    break
            if binned_label is None:  # if no bin matched the score
                binned_label = "Unassigned"  # assign 'Unassigned' label
            binned_labels.append(binned_label)
        return binned_labels
\end{lstlisting}

\begin{lstlisting}[language=Python, caption={\texttt{embedding\_model.py}}, label={prco:embedding-model}]
from transformers import AutoTokenizer, AutoModel
import torch

class EmbeddingModel:
    def __init__(self, model_name):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)

    def get_embedding(self, code_snippet):
        tokens = self.tokenizer(code_snippet, return_tensors="pt", 
                                truncation=True, padding=True)
        with torch.no_grad():
            outputs = self.model(**tokens)
        return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()
\end{lstlisting}

\begin{lstlisting}[language=Python, caption={\texttt{dimension\_reducer.py}}, label={prco:dimension-reducer}]
class DimensionReducer:
    def __init__(self, algorithm="umap", params=None):
        self.algorithm = algorithm
        self.params = params if params is not None else {}

    def reduce(self, embeddings):
        if self.algorithm == "pca":
            from sklearn.decomposition import PCA
            model = PCA(**self.params)
        elif self.algorithm == "tsne":
            from sklearn.manifold import TSNE
            model = TSNE(**self.params)
        elif self.algorithm == "umap":
            import umap
            model = umap.UMAP(**self.params)
        else:
            raise ValueError(f"Unsupported algorithm: {self.algorithm}")

        reduced_embeddings = model.fit_transform(embeddings)
        return reduced_embeddings
\end{lstlisting}

\begin{lstlisting}[language=Python, caption={\texttt{clustering\_engine.py}}, label={prco:clustering-engine}]
class ClusteringEngine:
    def __init__(self, algorithm="hdbscan", params=None):
        self.algorithm = algorithm
        self.params = params if params is not None else {}

    def cluster(self, reduced_embeddings):
        if self.algorithm == "kmeans":
            from sklearn.cluster import KMeans
            model = KMeans(**self.params)
        elif self.algorithm == "hdbscan":
            import hdbscan
            model = hdbscan.HDBSCAN(**self.params)
        else:
            raise ValueError(f"Unsupported algorithm: {self.algorithm}")

        labels = model.fit_predict(reduced_embeddings)
        return labels
\end{lstlisting}

\begin{lstlisting}[language=Python, caption={\texttt{evaluation\_metrics.py}}, label={prco:evaluation-metrics}]
from sklearn.metrics import silhouette_score
from sklearn.metrics import calinski_harabasz_score
from sklearn.metrics import davies_bouldin_score

class EvaluationMetrics:
    @staticmethod
    def evaluate(reduced_embeddings, labels):
        results = {}
        if len(set(labels)) > 1:
            results['silhouette'] = silhouette_score(
                reduced_embeddings, labels)
            results['calinski_harabasz'] = calinski_harabasz_score(
                reduced_embeddings, labels)
            results['davies_bouldin'] = davies_bouldin_score(
                reduced_embeddings, labels)
        else:
            results['silhouette'] = None
            results['calinski_harabasz'] = None
            results['davies_bouldin'] = None
        return results
\end{lstlisting}

\begin{lstlisting}[language=Python, caption={\texttt{advanced\_iteractive\_plot.py}}, label={prco:advanced-interactive-plot}]
import pandas as pd
import plotly.express as px

class AdvancedInteractivePlot:
    @staticmethod
    def plot(reduced_embeddings, labels, 
             filenames, parent_dirs, score_bins):
        df = pd.DataFrame({
            'filename': filenames,
            'parent_dir': parent_dirs,
            'cluster': labels,
            'score_bin': score_bins,
            'x': [e[0] for e in reduced_embeddings],
            'y': [e[1] for e in reduced_embeddings],
            # 'z': [e[2] for e in reduced_embeddings], # third dimension
        })

        # decomment for a 2D diagram
        fig = px.scatter(df, x='x', y='y',
                         color=df['cluster'].astype(str),
                         hover_data=['filename', 
                                     'parent_dir', 'score_bin'],
                         title="Interaktive Cluster-Visualisierung")
        
        # # decomment for a 3D diagram
        # fig = px.scatter_3d(
        #     df, x='x', y='y', z='z',
        #     color=df['cluster'].astype(str),
        #     hover_data=['filename', 'parent_dir', 'score_bin'],
        #     title="Interaktive 3D-Cluster-Visualisierung")
        
        fig.show()
\end{lstlisting}

\begin{lstlisting}[language=Python, caption={\texttt{report\_generator.py}}, label={prco:report-generator}]
import os

class ReportGenerator:
    @staticmethod
    def generate_report(filenames, parent_dirs, 
                        labels, score_bins, output_path):
        output_path = os.path.join(output_path, "cluster_report.csv")
        grouped = {}
        # group by score_bins and clusters
        for b, c, p_dir, f in zip(score_bins, labels,
                                   parent_dirs, filenames): 
            if b not in grouped:
                grouped[b] = {}
            if c not in grouped[b]:
                grouped[b][c] = []
            grouped[b][c].append((p_dir, f))
        # write score_bins, clusters and file data to csv-file
        with open(output_path, "w", encoding="utf-8") as f:
            for b in sorted(grouped.keys()):
                f.write(f"Score-Bin: {b}\n")
                for c in sorted(grouped[b].keys()):
                    f.write(f"Cluster {c}:\n")
                    for (p_dir, subfolder), filename in grouped[b][c]:
                        f.write(f"- {p_dir} - {subfolder} - {filename}\n")
                f.write("\n")
\end{lstlisting}